{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES.\n",
    "using Suppressor\n",
    "@suppress begin\n",
    "    using DataFrames\n",
    "    using LazyJSON\n",
    "    using GLM \n",
    "    using MLJ \n",
    "    using MLJBase\n",
    "    using CSV\n",
    "    using Serialization\n",
    "    using MLJScientificTypes\n",
    "    using CategoricalArrays\n",
    "    using MLJLinearModels\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES \n",
    "ROOT_DIR = dirname(pwd())\n",
    "MODEL_INPUTS_OUTPUTS = joinpath(ROOT_DIR, \"model_inputs_outputs\")\n",
    "INPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"inputs\")\n",
    "INPUT_SCHEMA_DIR = joinpath(INPUT_DIR, \"schema\")\n",
    "DATA_DIR = joinpath(INPUT_DIR, \"data\")\n",
    "OUTPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"outputs\")\n",
    "TRAIN_DIR = joinpath(DATA_DIR, \"training\")\n",
    "TEST_DIR = joinpath(DATA_DIR, \"testing\")\n",
    "MODEL_PATH = joinpath(MODEL_INPUTS_OUTPUTS, \"model\")\n",
    "MODEL_ARTIFACTS_PATH = joinpath(MODEL_PATH, \"artifacts\")\n",
    "OHE_ENCODER_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"ohe.ser\")\n",
    "PREDICTOR_DIR_PATH = joinpath(MODEL_ARTIFACTS_PATH, \"predictor\")\n",
    "PREDICTOR_FILE_PATH = joinpath(PREDICTOR_DIR_PATH, \"predictor.ser\")\n",
    "IMPUTATION_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"imputation.ser\")\n",
    "TOP_CATEGORIES = joinpath(MODEL_ARTIFACTS_PATH, \"top_categories.ser\")\n",
    "PREDICTIONS_DIR = joinpath(OUTPUT_DIR, \"predictions\")\n",
    "PREDICTIONS_FILE = joinpath(PREDICTIONS_DIR, \"predictions.csv\")\n",
    "TARGET_LEVELS = joinpath(MODEL_ARTIFACTS_PATH, \"target_levels.ser\")\n",
    "TARGET_MAPPING = joinpath(MODEL_ARTIFACTS_PATH, \"target_mapping.ser\")\n",
    "\n",
    "\n",
    "if !isdir(MODEL_ARTIFACTS_PATH)\n",
    "    mkdir(MODEL_ARTIFACTS_PATH)\n",
    "end\n",
    "if !isdir(PREDICTOR_DIR_PATH)\n",
    "    mkdir(PREDICTOR_DIR_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a schema from a JSON file and extracting features\n",
    "file_name = first(filter(x -> endswith(x, \"json\"), readdir(INPUT_SCHEMA_DIR)))\n",
    "schema_path = joinpath(INPUT_SCHEMA_DIR, file_name)\n",
    "schema_string = read(schema_path, String)  # Read file content as a string\n",
    "schema = LazyJSON.parse(schema_string)\n",
    "features = schema[\"features\"]\n",
    "\n",
    "# Identifying numeric, categorical, and nullable features\n",
    "numeric_features = String[]\n",
    "categorical_features = String[]\n",
    "nullable_features = String[]\n",
    "\n",
    "for f in features\n",
    "    if f[\"dataType\"] == \"CATEGORICAL\"\n",
    "        push!(categorical_features, f[\"name\"])\n",
    "    else\n",
    "        push!(numeric_features, f[\"name\"])\n",
    "    end\n",
    "    if f[\"nullable\"]\n",
    "        push!(nullable_features, f[\"name\"])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Extracting ID and target features\n",
    "id_feature = schema[\"id\"][\"name\"]\n",
    "target_feature = schema[\"target\"][\"name\"]\n",
    "target_classes = schema[\"target\"][\"classes\"]\n",
    "\n",
    "if length(target_classes) == 2\n",
    "    negative_class = target_classes[1]\n",
    "    positive_class = target_classes[2]\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>40 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>color</th><th>number</th></tr><tr><th></th><th title=\"String7\">String7</th><th title=\"Union{Missing, String7}\">String7?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>DQYUN3</td><td>Red</td><td>75.0</td></tr><tr><th>2</th><td>QIP98Q</td><td>Red</td><td>87.0</td></tr><tr><th>3</th><td>OAEDOE</td><td>Green</td><td>56.0</td></tr><tr><th>4</th><td>ZFV8YU</td><td>Red</td><td>46.0</td></tr><tr><th>5</th><td>L9EKA0</td><td>Blue</td><td>59.0</td></tr><tr><th>6</th><td>9VW3RT</td><td>Green</td><td>68.0</td></tr><tr><th>7</th><td>MQC1A7</td><td>Red</td><td>31.0</td></tr><tr><th>8</th><td>5SOWOM</td><td>Green</td><td>63.0</td></tr><tr><th>9</th><td>76RKQ4</td><td>Blue</td><td>33.0</td></tr><tr><th>10</th><td>EPZHPC</td><td>Blue</td><td>93.0</td></tr><tr><th>11</th><td>6Z8VBH</td><td>Green</td><td>89.0</td></tr><tr><th>12</th><td>IY3X80</td><td>Green</td><td>46.0</td></tr><tr><th>13</th><td>Q3QA3S</td><td><em>missing</em></td><td>53.0</td></tr><tr><th>14</th><td>CP4E30</td><td>Blue</td><td>1.0</td></tr><tr><th>15</th><td>ZRMH3F</td><td>Blue</td><td>86.0</td></tr><tr><th>16</th><td>AQ8H3X</td><td>Green</td><td><em>missing</em></td></tr><tr><th>17</th><td>IQK291</td><td>Blue</td><td>71.0</td></tr><tr><th>18</th><td>WV98Y3</td><td>Blue</td><td>49.0</td></tr><tr><th>19</th><td>I379U2</td><td>Green</td><td>37.0</td></tr><tr><th>20</th><td>WU16HY</td><td>Green</td><td>23.0</td></tr><tr><th>21</th><td>JJTFPH</td><td>Blue</td><td>17.0</td></tr><tr><th>22</th><td>1ZXOI6</td><td>Green</td><td>96.0</td></tr><tr><th>23</th><td>44P39J</td><td>Red</td><td>19.0</td></tr><tr><th>24</th><td>K3I8BZ</td><td>Blue</td><td>33.0</td></tr><tr><th>25</th><td>ZVRERW</td><td>Green</td><td>57.0</td></tr><tr><th>26</th><td>PGW90J</td><td>Green</td><td>39.0</td></tr><tr><th>27</th><td>2QPR75</td><td>Red</td><td>9.0</td></tr><tr><th>28</th><td>QLQCG1</td><td>Green</td><td>50.0</td></tr><tr><th>29</th><td>90O7Y2</td><td>Red</td><td>33.0</td></tr><tr><th>30</th><td>JEDKTS</td><td>Red</td><td>38.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& id & color & number\\\\\n",
       "\t\\hline\n",
       "\t& String7 & String7? & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & DQYUN3 & Red & 75.0 \\\\\n",
       "\t2 & QIP98Q & Red & 87.0 \\\\\n",
       "\t3 & OAEDOE & Green & 56.0 \\\\\n",
       "\t4 & ZFV8YU & Red & 46.0 \\\\\n",
       "\t5 & L9EKA0 & Blue & 59.0 \\\\\n",
       "\t6 & 9VW3RT & Green & 68.0 \\\\\n",
       "\t7 & MQC1A7 & Red & 31.0 \\\\\n",
       "\t8 & 5SOWOM & Green & 63.0 \\\\\n",
       "\t9 & 76RKQ4 & Blue & 33.0 \\\\\n",
       "\t10 & EPZHPC & Blue & 93.0 \\\\\n",
       "\t11 & 6Z8VBH & Green & 89.0 \\\\\n",
       "\t12 & IY3X80 & Green & 46.0 \\\\\n",
       "\t13 & Q3QA3S & \\emph{missing} & 53.0 \\\\\n",
       "\t14 & CP4E30 & Blue & 1.0 \\\\\n",
       "\t15 & ZRMH3F & Blue & 86.0 \\\\\n",
       "\t16 & AQ8H3X & Green & \\emph{missing} \\\\\n",
       "\t17 & IQK291 & Blue & 71.0 \\\\\n",
       "\t18 & WV98Y3 & Blue & 49.0 \\\\\n",
       "\t19 & I379U2 & Green & 37.0 \\\\\n",
       "\t20 & WU16HY & Green & 23.0 \\\\\n",
       "\t21 & JJTFPH & Blue & 17.0 \\\\\n",
       "\t22 & 1ZXOI6 & Green & 96.0 \\\\\n",
       "\t23 & 44P39J & Red & 19.0 \\\\\n",
       "\t24 & K3I8BZ & Blue & 33.0 \\\\\n",
       "\t25 & ZVRERW & Green & 57.0 \\\\\n",
       "\t26 & PGW90J & Green & 39.0 \\\\\n",
       "\t27 & 2QPR75 & Red & 9.0 \\\\\n",
       "\t28 & QLQCG1 & Green & 50.0 \\\\\n",
       "\t29 & 90O7Y2 & Red & 33.0 \\\\\n",
       "\t30 & JEDKTS & Red & 38.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m40×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m id      \u001b[0m\u001b[1m color    \u001b[0m\u001b[1m number   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String7 \u001b[0m\u001b[90m String7? \u001b[0m\u001b[90m Float64? \u001b[0m\n",
       "─────┼─────────────────────────────\n",
       "   1 │ DQYUN3   Red           75.0\n",
       "   2 │ QIP98Q   Red           87.0\n",
       "   3 │ OAEDOE   Green         56.0\n",
       "   4 │ ZFV8YU   Red           46.0\n",
       "   5 │ L9EKA0   Blue          59.0\n",
       "   6 │ 9VW3RT   Green         68.0\n",
       "   7 │ MQC1A7   Red           31.0\n",
       "   8 │ 5SOWOM   Green         63.0\n",
       "   9 │ 76RKQ4   Blue          33.0\n",
       "  10 │ EPZHPC   Blue          93.0\n",
       "  11 │ 6Z8VBH   Green         89.0\n",
       "  ⋮  │    ⋮        ⋮         ⋮\n",
       "  31 │ OGYR3X   Blue          81.0\n",
       "  32 │ 1EYY37   Green          1.0\n",
       "  33 │ F1RCAV   Blue          96.0\n",
       "  34 │ 322N64   Green         90.0\n",
       "  35 │ 0V6RAS   Green         35.0\n",
       "  36 │ E6VA05   Blue          93.0\n",
       "  37 │ 1UQBFO   Blue           8.0\n",
       "  38 │ 2RL15F   Blue          27.0\n",
       "  39 │ YP5JO3   Green         46.0\n",
       "  40 │ KFS6VF   Green         60.0\n",
       "\u001b[36m                    19 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = filter(x -> occursin(\".csv\", x), readdir(TEST_DIR))[1]\n",
    "file_path = joinpath(TEST_DIR, file_name)\n",
    "df = DataFrame(CSV.File(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Note that when we work with testing data, we have to impute using the same values learned during training. This is to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>40 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>color</th><th>number</th></tr><tr><th></th><th title=\"String7\">String7</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>Red</td><td>75.0</td></tr><tr><th>2</th><td>Red</td><td>87.0</td></tr><tr><th>3</th><td>Green</td><td>56.0</td></tr><tr><th>4</th><td>Red</td><td>46.0</td></tr><tr><th>5</th><td>Blue</td><td>59.0</td></tr><tr><th>6</th><td>Green</td><td>68.0</td></tr><tr><th>7</th><td>Red</td><td>31.0</td></tr><tr><th>8</th><td>Green</td><td>63.0</td></tr><tr><th>9</th><td>Blue</td><td>33.0</td></tr><tr><th>10</th><td>Blue</td><td>93.0</td></tr><tr><th>11</th><td>Green</td><td>89.0</td></tr><tr><th>12</th><td>Green</td><td>46.0</td></tr><tr><th>13</th><td>Blue</td><td>53.0</td></tr><tr><th>14</th><td>Blue</td><td>1.0</td></tr><tr><th>15</th><td>Blue</td><td>86.0</td></tr><tr><th>16</th><td>Green</td><td>47.0</td></tr><tr><th>17</th><td>Blue</td><td>71.0</td></tr><tr><th>18</th><td>Blue</td><td>49.0</td></tr><tr><th>19</th><td>Green</td><td>37.0</td></tr><tr><th>20</th><td>Green</td><td>23.0</td></tr><tr><th>21</th><td>Blue</td><td>17.0</td></tr><tr><th>22</th><td>Green</td><td>96.0</td></tr><tr><th>23</th><td>Red</td><td>19.0</td></tr><tr><th>24</th><td>Blue</td><td>33.0</td></tr><tr><th>25</th><td>Green</td><td>57.0</td></tr><tr><th>26</th><td>Green</td><td>39.0</td></tr><tr><th>27</th><td>Red</td><td>9.0</td></tr><tr><th>28</th><td>Green</td><td>50.0</td></tr><tr><th>29</th><td>Red</td><td>33.0</td></tr><tr><th>30</th><td>Red</td><td>38.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& color & number\\\\\n",
       "\t\\hline\n",
       "\t& String7 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Red & 75.0 \\\\\n",
       "\t2 & Red & 87.0 \\\\\n",
       "\t3 & Green & 56.0 \\\\\n",
       "\t4 & Red & 46.0 \\\\\n",
       "\t5 & Blue & 59.0 \\\\\n",
       "\t6 & Green & 68.0 \\\\\n",
       "\t7 & Red & 31.0 \\\\\n",
       "\t8 & Green & 63.0 \\\\\n",
       "\t9 & Blue & 33.0 \\\\\n",
       "\t10 & Blue & 93.0 \\\\\n",
       "\t11 & Green & 89.0 \\\\\n",
       "\t12 & Green & 46.0 \\\\\n",
       "\t13 & Blue & 53.0 \\\\\n",
       "\t14 & Blue & 1.0 \\\\\n",
       "\t15 & Blue & 86.0 \\\\\n",
       "\t16 & Green & 47.0 \\\\\n",
       "\t17 & Blue & 71.0 \\\\\n",
       "\t18 & Blue & 49.0 \\\\\n",
       "\t19 & Green & 37.0 \\\\\n",
       "\t20 & Green & 23.0 \\\\\n",
       "\t21 & Blue & 17.0 \\\\\n",
       "\t22 & Green & 96.0 \\\\\n",
       "\t23 & Red & 19.0 \\\\\n",
       "\t24 & Blue & 33.0 \\\\\n",
       "\t25 & Green & 57.0 \\\\\n",
       "\t26 & Green & 39.0 \\\\\n",
       "\t27 & Red & 9.0 \\\\\n",
       "\t28 & Green & 50.0 \\\\\n",
       "\t29 & Red & 33.0 \\\\\n",
       "\t30 & Red & 38.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m40×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m color   \u001b[0m\u001b[1m number  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String7 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼──────────────────\n",
       "   1 │ Red         75.0\n",
       "   2 │ Red         87.0\n",
       "   3 │ Green       56.0\n",
       "   4 │ Red         46.0\n",
       "   5 │ Blue        59.0\n",
       "   6 │ Green       68.0\n",
       "   7 │ Red         31.0\n",
       "   8 │ Green       63.0\n",
       "   9 │ Blue        33.0\n",
       "  10 │ Blue        93.0\n",
       "  11 │ Green       89.0\n",
       "  ⋮  │    ⋮        ⋮\n",
       "  31 │ Blue        81.0\n",
       "  32 │ Green        1.0\n",
       "  33 │ Blue        96.0\n",
       "  34 │ Green       90.0\n",
       "  35 │ Green       35.0\n",
       "  36 │ Blue        93.0\n",
       "  37 │ Blue         8.0\n",
       "  38 │ Blue        27.0\n",
       "  39 │ Green       46.0\n",
       "  40 │ Green       60.0\n",
       "\u001b[36m         19 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_values = open(deserialize, IMPUTATION_FILE)\n",
    "for column in nullable_features\n",
    "    df[!, Symbol(column)] .= coalesce.(df[!, Symbol(column)], get(imputation_values, string(column), missing))\n",
    "end\n",
    "\n",
    "# Saving the id column in a different variable\n",
    "ids = df[!, Symbol(id_feature)]\n",
    "\n",
    "# Dropping the id and target from the DataFrame\n",
    "select!(df, Not([Symbol(id_feature)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "We encode the data using the same encoder that we saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_top_categories = open(deserialize, TOP_CATEGORIES)\n",
    "\n",
    "# Function to one-hot encode only the top 10 categories\n",
    "function one_hot_top_categories!(df, top_categories)\n",
    "    for (feature, top_cats) in top_categories\n",
    "        if length(top_cats) == 2  # Handle the binary case\n",
    "            # Assuming the first category in top_cats is treated as 'true'\n",
    "            new_col_name = \"$(feature)_binary\"\n",
    "            df[!, new_col_name] = df[!, feature] .== top_cats[1]\n",
    "        else  # Handle the general case\n",
    "            for cat in top_cats\n",
    "                new_col_name = \"$(feature)_$(cat)\"\n",
    "                df[!, new_col_name] = df[!, feature] .== cat\n",
    "            end\n",
    "        end\n",
    "        select!(df, Not(Symbol(feature)))  # Drop the original feature column\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "one_hot_top_categories!(df, loaded_top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "Using the model saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = open(deserialize, PREDICTOR_FILE_PATH)\n",
    "target_levels = open(deserialize, TARGET_LEVELS)\n",
    "\n",
    "\n",
    "# if length(target_classes) == 2\n",
    "#     loaded_mapping = open(deserialize, TARGET_MAPPING)\n",
    "#     log_odds_predictions = GLM.predict(model, convert(Matrix{Float64}, Matrix(df)))\n",
    "#     probabilities = 1 ./ (1 .+ exp.(-log_odds_predictions))\n",
    "#     threshold = 0.5\n",
    "#     integer_predictions = ifelse.(probabilities .> threshold, 1, 0)\n",
    "#     label_predictions = [loaded_mapping[pred] for pred in integer_predictions]\n",
    "#     label_predictions = target_levels[integer_predictions .+ 1]\n",
    "\n",
    "#     result_df = DataFrame()\n",
    "#     result_df[!, Symbol(negative_class)] = 1 .- probabilities\n",
    "#     result_df[!, Symbol(positive_class)] = probabilities\n",
    "#     result_df[!, id_feature] = ids\n",
    "#     result_df\n",
    "\n",
    "\n",
    "# else\n",
    "probabilities = MLJ.predict(model, df)\n",
    "\n",
    "# Number of classes\n",
    "n_classes = length(target_classes)\n",
    "\n",
    "# Extract probabilities for each class\n",
    "probs_matrix = hcat([pdf.(probabilities, i) for i in 0:(n_classes-1)]...)\n",
    "\n",
    "# Create the DataFrame\n",
    "result_df = DataFrame(probs_matrix, Symbol.(target_levels))\n",
    "result_df[!, id_feature] = ids\n",
    "result_df\n",
    "\n",
    "# end\n",
    "CSV.write(PREDICTIONS_FILE, result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
